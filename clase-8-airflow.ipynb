{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Airflow\n",
    "Airflow es un software elaborado por Apache para crear y manipular flows de datos y orquestar pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalacion\n",
    "\n",
    "Seguir pasos de QuickStart: https://airflow.apache.org/docs/apache-airflow/stable/start.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crear un usuario en airflow standalone para ver la UI\n",
    "\n",
    "Correr el siguiente comando en el entorno donde este instalado airflow para ver la UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# airflow users create --role Admin --username <usuario> --email <mail> --firstname <nombre> --lastname <apellido> --password <pass>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conceptos\n",
    "Documentacion oficial: https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/dags.html#dags\n",
    "\n",
    "### DAG\n",
    "\n",
    "Un DAG (Grafo dirigido Aciclico) es el concepto base de Airflow, recolectando las tareas, organizando dependencias y relaciones para determinar como deben correr. \n",
    "\n",
    "Ejemplo basico de un DAG:\n",
    "\n",
    "![alt text](https://airflow.apache.org/docs/apache-airflow/stable/_images/basic-dag.png)\n",
    "\n",
    "Define cuatro tareas - A, B, C y D - y determina el orden en el que tienen que correr, y que tareas dependen de otras. Tambien dira que tan seguido se debe correr el DAG. Quizas es \"cada 5 minutos comenzando ma√±ana\" o \"todos los dias desde Enero 2025\"\n",
    "\n",
    "El DAG no conoce lo que pasa dentro de las tareas, solo se encarga en como ejecutarlas: en que orden, cuantas veces, si hay timeouts, etcetera. \n",
    "\n",
    "### Deploy de componentes\n",
    "\n",
    "Cada componente de Airflow son aplicaciones en Python que pueden ser deployadas de distintas maneras. Airflow puede correr en una unica maquina o de manera distribuida, siendo esta ultima la recomendada en ambientes de produccion que tienen la posibilidad de escalar en carga de trabajo. Usualmente el uso de Airflow esta ligado a este tipo de contextos. Se puede armar un entorno de flujos muy simple con una unica maquina o muy complejo que permita el escalado de una manera mas seamless. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sara",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
