{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Part 0: Single Threaded"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(442, 11)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>age</th>\n","      <th>sex</th>\n","      <th>bmi</th>\n","      <th>bp</th>\n","      <th>s1</th>\n","      <th>s2</th>\n","      <th>s3</th>\n","      <th>s4</th>\n","      <th>s5</th>\n","      <th>s6</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>23</th>\n","      <td>0.045341</td>\n","      <td>0.050680</td>\n","      <td>0.060618</td>\n","      <td>0.031065</td>\n","      <td>0.028702</td>\n","      <td>-0.047347</td>\n","      <td>-0.054446</td>\n","      <td>0.071210</td>\n","      <td>0.133597</td>\n","      <td>0.135612</td>\n","      <td>245.0</td>\n","    </tr>\n","    <tr>\n","      <th>341</th>\n","      <td>0.030811</td>\n","      <td>0.050680</td>\n","      <td>0.059541</td>\n","      <td>0.056301</td>\n","      <td>-0.022208</td>\n","      <td>0.001191</td>\n","      <td>-0.032356</td>\n","      <td>-0.002592</td>\n","      <td>-0.024795</td>\n","      <td>-0.017646</td>\n","      <td>263.0</td>\n","    </tr>\n","    <tr>\n","      <th>124</th>\n","      <td>-0.005515</td>\n","      <td>-0.044642</td>\n","      <td>0.023973</td>\n","      <td>0.008101</td>\n","      <td>-0.034592</td>\n","      <td>-0.038892</td>\n","      <td>0.022869</td>\n","      <td>-0.039493</td>\n","      <td>-0.015999</td>\n","      <td>-0.013504</td>\n","      <td>121.0</td>\n","    </tr>\n","    <tr>\n","      <th>419</th>\n","      <td>-0.020045</td>\n","      <td>-0.044642</td>\n","      <td>-0.054707</td>\n","      <td>-0.053870</td>\n","      <td>-0.066239</td>\n","      <td>-0.057367</td>\n","      <td>0.011824</td>\n","      <td>-0.039493</td>\n","      <td>-0.074093</td>\n","      <td>-0.005220</td>\n","      <td>42.0</td>\n","    </tr>\n","    <tr>\n","      <th>271</th>\n","      <td>0.038076</td>\n","      <td>0.050680</td>\n","      <td>0.008883</td>\n","      <td>0.042529</td>\n","      <td>-0.042848</td>\n","      <td>-0.021042</td>\n","      <td>-0.039719</td>\n","      <td>-0.002592</td>\n","      <td>-0.018114</td>\n","      <td>0.007207</td>\n","      <td>127.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          age       sex       bmi        bp        s1        s2        s3  \\\n","23   0.045341  0.050680  0.060618  0.031065  0.028702 -0.047347 -0.054446   \n","341  0.030811  0.050680  0.059541  0.056301 -0.022208  0.001191 -0.032356   \n","124 -0.005515 -0.044642  0.023973  0.008101 -0.034592 -0.038892  0.022869   \n","419 -0.020045 -0.044642 -0.054707 -0.053870 -0.066239 -0.057367  0.011824   \n","271  0.038076  0.050680  0.008883  0.042529 -0.042848 -0.021042 -0.039719   \n","\n","           s4        s5        s6  target  \n","23   0.071210  0.133597  0.135612   245.0  \n","341 -0.002592 -0.024795 -0.017646   263.0  \n","124 -0.039493 -0.015999 -0.013504   121.0  \n","419 -0.039493 -0.074093 -0.005220    42.0  \n","271 -0.002592 -0.018114  0.007207   127.0  "]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["import numpy as np\n","import pandas as pd\n","\n","# load the diab data set|\n","from sklearn.datasets import load_diabetes\n","diab = load_diabetes()\n","\n","# convert to a Pandas Data Frame\n","diab_pd = pd.DataFrame(data= np.c_[diab['data'],diab['target']], \n","                         columns= np.append(diab['feature_names'], 'target')).sample(frac=1)\n","print(diab_pd.shape)\n","diab_pd.head(5)\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["R-squared: 0.44972024389022563\n","MAE: 43.4355042106305\n"]},{"name":"stderr","output_type":"stream","text":["/var/folders/s9/pkq_ftrs45d7vxwnrztcln6r0000gn/T/ipykernel_36267/3603432283.py:2: DeprecationWarning: Please import `pearsonr` from the `scipy.stats` namespace; the `scipy.stats.stats` namespace is deprecated and will be removed in SciPy 2.0.0.\n","  from scipy.stats.stats import pearsonr\n"]}],"source":["from sklearn.linear_model import LinearRegression\n","from scipy.stats.stats import pearsonr\n","\n","# split into data and label arrays \n","y = diab_pd['target']\n","X = diab_pd.drop(['target'], axis=1)\n","\n","# create training (~80%) and test data sets\n","X_train = X[:400]\n","X_test = X[400:]\n","y_train = y[:400]\n","y_test = y[400:]\n","\n","# train a classifier \n","lr = LinearRegression()\n","model = lr.fit(X_train, y_train)\n","\n","# make predictions\n","y_pred = model.predict(X_test)\n","\n","# error metrics\n","r = pearsonr(y_pred, y_test)\n","mae = sum(abs(y_pred - y_test))/len(y_test)\n","print(\"R-squared: \" + str(r[0]**2))\n","print(\"MAE: \" + str(mae))\n"]},{"cell_type":"markdown","metadata":{},"source":["# Part 1: Native Spark"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/html":["<style scoped>\n","  .table-result-container {\n","    max-height: 300px;\n","    overflow: auto;\n","  }\n","  table, th, td {\n","    border: 1px solid black;\n","    border-collapse: collapse;\n","  }\n","  th, td {\n","    padding: 5px;\n","  }\n","  th {\n","    text-align: left;\n","  }\n","</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>CRIM</th><th>ZN</th><th>INDUS</th><th>CHAS</th><th>NOX</th><th>RM</th><th>AGE</th><th>DIS</th><th>RAD</th><th>TAX</th><th>PTRATIO</th><th>B</th><th>LSTAT</th><th>target</th></tr></thead><tbody><tr><td>0.03537</td><td>34.0</td><td>6.09</td><td>0.0</td><td>0.433</td><td>6.59</td><td>40.4</td><td>5.4917</td><td>7.0</td><td>329.0</td><td>16.1</td><td>395.75</td><td>9.5</td><td>22.0</td></tr><tr><td>0.12329</td><td>0.0</td><td>10.01</td><td>0.0</td><td>0.547</td><td>5.913</td><td>92.9</td><td>2.3534</td><td>6.0</td><td>432.0</td><td>17.8</td><td>394.95</td><td>16.21</td><td>18.8</td></tr><tr><td>23.6482</td><td>0.0</td><td>18.1</td><td>0.0</td><td>0.671</td><td>6.38</td><td>96.2</td><td>1.3861</td><td>24.0</td><td>666.0</td><td>20.2</td><td>396.9</td><td>23.69</td><td>13.1</td></tr><tr><td>4.42228</td><td>0.0</td><td>18.1</td><td>0.0</td><td>0.584</td><td>6.003</td><td>94.5</td><td>2.5403</td><td>24.0</td><td>666.0</td><td>20.2</td><td>331.29</td><td>21.32</td><td>19.1</td></tr><tr><td>0.27957</td><td>0.0</td><td>9.69</td><td>0.0</td><td>0.585</td><td>5.926</td><td>42.6</td><td>2.3817</td><td>6.0</td><td>391.0</td><td>19.2</td><td>396.9</td><td>13.59</td><td>24.5</td></tr></tbody></table></div>"]},"metadata":{},"output_type":"display_data"}],"source":["# convert to a Spark data frame\n","diab_sp = spark.createDataFrame(diab_pd)\n","display(diab_sp.take(5))\n"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/html":["<style scoped>\n","  .table-result-container {\n","    max-height: 300px;\n","    overflow: auto;\n","  }\n","  table, th, td {\n","    border: 1px solid black;\n","    border-collapse: collapse;\n","  }\n","  th, td {\n","    padding: 5px;\n","  }\n","  th {\n","    text-align: left;\n","  }\n","</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>features</th><th>target</th></tr></thead><tbody><tr><td>List(1, 13, List(), List(0.03537, 34.0, 6.09, 0.0, 0.433, 6.59, 40.4, 5.4917, 7.0, 329.0, 16.1, 395.75, 9.5))</td><td>22.0</td></tr><tr><td>List(1, 13, List(), List(0.12329, 0.0, 10.01, 0.0, 0.547, 5.913, 92.9, 2.3534, 6.0, 432.0, 17.8, 394.95, 16.21))</td><td>18.8</td></tr><tr><td>List(1, 13, List(), List(23.6482, 0.0, 18.1, 0.0, 0.671, 6.38, 96.2, 1.3861, 24.0, 666.0, 20.2, 396.9, 23.69))</td><td>13.1</td></tr><tr><td>List(1, 13, List(), List(4.42228, 0.0, 18.1, 0.0, 0.584, 6.003, 94.5, 2.5403, 24.0, 666.0, 20.2, 331.29, 21.32))</td><td>19.1</td></tr><tr><td>List(1, 13, List(), List(0.27957, 0.0, 9.69, 0.0, 0.585, 5.926, 42.6, 2.3817, 6.0, 391.0, 19.2, 396.9, 13.59))</td><td>24.5</td></tr></tbody></table></div>"]},"metadata":{},"output_type":"display_data"}],"source":["from pyspark.ml.feature import VectorAssembler\n","\n","# split into training and test spark data frames\n","diab_train = spark.createDataFrame(diab_pd[:400])\n","diab_test = spark.createDataFrame(diab_pd[400:])\n","\n","# convert to vector representation for MLlib\n","assembler = VectorAssembler(inputCols= diab_train.schema.names[:(diab_pd.shape[1] - 1)],  outputCol=\"features\" )\n","diab_train = assembler.transform(diab_train).select('features', 'target') \n","diab_test = assembler.transform(diab_test).select('features', 'target') \n","\n","display(diab_train.take(5))"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>\n","<div class=\"ansiout\">R-sqaured: 0.8063433683277974\n","</div>"]},"metadata":{},"output_type":"display_data"}],"source":["# linear regresion with Spark\n","from pyspark.ml.regression import LinearRegression\n","\n","# linear regression \n","lr = LinearRegression(maxIter=10, regParam=0.1, elasticNetParam=0.5, labelCol=\"target\")\n","\n","# Fit the model\n","model = lr.fit(diab_train)\n","diab_pred = model.transform(diab_test)\n","\n","# calculate results \n","r = diab_pred.stat.corr(\"prediction\", \"target\")\n","print(\"R-sqaured: \" + str(r**2))\n"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>\n","<div class=\"ansiout\">R-sqaured: 0.8148948560944629\n","</div>"]},"metadata":{},"output_type":"display_data"}],"source":["from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n","from pyspark.ml.evaluation import RegressionEvaluator\n","\n","crossval = CrossValidator(estimator=LinearRegression(labelCol = \"target\"),  \n","                           estimatorParamMaps=ParamGridBuilder().addGrid(LinearRegression.elasticNetParam, [0, 0.5, 1.0]).build(),\n","                           evaluator=RegressionEvaluator(labelCol = \"target\", metricName = \"r2\"),\n","                           numFolds=10)\n","\n","# cross validate the model and select the best fit\n","cvModel = crossval.fit(diab_train) \n","model = cvModel.bestModel\n","\n","# calculate results \n","diab_pred = model.transform(diab_test)\n","r = diab_pred.stat.corr(\"prediction\", \"target\")\n","print(\"R-sqaured: \" + str(r**2))\n"]},{"cell_type":"markdown","metadata":{},"source":["# Part 2: Thread Pools"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>\n","<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">7</span><span class=\"ansired\">]: </span>\n","[[10, 0.92121913976894299],\n"," [20, 0.92413752558900675],\n"," [50, 0.92705124846648523]]\n","</div>"]},"metadata":{},"output_type":"display_data"}],"source":["# sklearn version \n","from sklearn.ensemble import RandomForestRegressor as RFR\n","from multiprocessing.pool import ThreadPool\n","\n","# allow up to 5 concurrent threads\n","pool = ThreadPool(5)\n","\n","# hyperparameters to test out (n_trees)\n","parameters = [ 10, 20, 50]\n","\n","# define a function to train a RF model and return metrics \n","def sklearn_random_forest(trees, X_train, X_test, y_train, y_test):\n","\n","    # train a random forest regressor with the specified number of trees\n","    rf= RFR(n_estimators = trees)\n","    model = rf.fit(X_train, y_train)\n","\n","    # make predictions\n","    y_pred = model.predict(X_test)\n","    r = pearsonr(y_pred, y_test)\n","\n","    # return the number of trees, and the R value \n","    return [trees, r[0]**2]  \n","\n","# run the tasks \n","pool.map(lambda trees: sklearn_random_forest(trees, X_train, X_test, y_train, y_test), parameters)\n","\n","  "]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>\n","<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">8</span><span class=\"ansired\">]: </span>[[10, 0.9237724296567057], [20, 0.9180495321606045], [50, 0.9268564908071572]]\n","</div>"]},"metadata":{},"output_type":"display_data"}],"source":["# spark version\n","from pyspark.ml.regression import RandomForestRegressor\n","\n","# define a function to train a RF model and return metrics \n","def mllib_random_forest(trees, diab_train, diab_test):\n","\n","    # train a random forest regressor with the specified number of trees\n","    rf = RandomForestRegressor(numTrees = trees, labelCol=\"target\")\n","    model = rf.fit(diab_train)\n","\n","    # make predictions\n","    diab_pred = model.transform(diab_test)\n","    r = diab_pred.stat.corr(\"prediction\", \"target\")\n","\n","    # return the number of trees, and the R value \n","    return [trees, r**2]\n","  \n","# run the tasks \n","pool.map(lambda trees: mllib_random_forest(trees, diab_train, diab_test), parameters)\n","  "]},{"cell_type":"markdown","metadata":{},"source":["# Part 3: Pandas UDF"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>\n","<div class=\"ansiout\">[Row(trees=20, r_squared=0.8633562691646341), Row(trees=50, r_squared=0.866335129308371), Row(trees=11, r_squared=0.8257884742588874)]\n","</div>"]},"metadata":{},"output_type":"display_data"}],"source":["from pyspark.sql.functions import pandas_udf, PandasUDFType\n","from pyspark.sql.types import *\n","\n","# setup the spark data frame as a table\n","diab_sp.createOrReplaceTempView(\"diab\")\n","\n","# add train/test label and expand the data set by 3x (each num trees parameter)\n","full_df = spark.sql(\"\"\"\n","  select *\n","  from (\n","    select *, case when rand() < 0.8 then 1 else 0 end as training \n","    from diab\n","  ) b\n","  cross join (\n","      select 11 as trees union all select 20 as trees union all select 50 as trees)\n","\"\"\")\n","\n","schema = StructType([StructField('trees', LongType(), True),\n","                     StructField('r_squared', DoubleType(), True)])  \n","\n","@pandas_udf(schema, PandasUDFType.GROUPED_MAP)\n","def train_RF(diab_pd):\n","    trees = diab_pd['trees'].unique()[0]\n","\n","    # get the train and test groups \n","    diab_train = diab_pd[diab_pd['training'] == 1]\n","    diab_test = diab_pd[diab_pd['training'] == 0] \n","        \n","    # create data and label groups \n","    y_train = diab_train['target']\n","    X_train = diab_train.drop(['target'], axis=1)\n","    y_test = diab_test['target']\n","    X_test = diab_test.drop(['target'], axis=1)\n","   \n","    # train a classifier \n","    rf= RFR(n_estimators = trees)\n","    model = rf.fit(X_train, y_train)\n","\n","    # make predictions\n","    y_pred = model.predict(X_test)\n","    r = pearsonr(y_pred, y_test)\n","    \n","    # return the number of trees, and the R value \n","    return pd.DataFrame({'trees': trees, 'r_squared': (r[0]**2)}, index=[0])\n","  \n","# use the Pandas UDF\n","results = full_df.groupby('trees').apply(train_RF)\n","\n","# print the results \n","print(results.take(3))\n"]}],"metadata":{"kernelspec":{"display_name":"sara","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"name":"PySpark_Parallel","notebookId":362889436276929},"nbformat":4,"nbformat_minor":0}
